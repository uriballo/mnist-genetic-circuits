{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-04T21:07:47.497035Z",
     "start_time": "2024-03-04T21:07:44.052410Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Subset\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "db5d0afd4c05e6ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-04T21:07:47.509937Z",
     "start_time": "2024-03-04T21:07:47.508054Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_train = 6000\n",
    "n_test  = 1000\n",
    "batch_size = 256\n",
    "n_epochs = 20\n",
    "\n",
    "lr = 0.01\n",
    "gamma = 0.985"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aede27153e053275",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-04T21:07:47.889649Z",
     "start_time": "2024-03-04T21:07:47.527205Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_dataset(n_train, n_test, batch_size):\n",
    "    \"\"\"\n",
    "    Loads train & test sets from MNIST with user-specified sizes.\n",
    "\n",
    "    Args:\n",
    "        n_train (int): Desired number of samples in the training set.\n",
    "        n_test (int): Desired number of samples in the testing set.\n",
    "        batch_size (int): Batch size for the DataLoaders.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (train_loader, test_loader) where each loader is a\n",
    "               torch.utils.data.DataLoader.\n",
    "    \"\"\"\n",
    "    # Define transformations for the dataset\n",
    "    transform = transforms.Compose([transforms.ToTensor(), \n",
    "                                    transforms.Normalize((0.5,), (0.5,)),\n",
    "                                    transforms.Lambda(lambda img: F.interpolate(img.unsqueeze(0), size=(14, 14), \n",
    "                                        mode='bilinear', align_corners=False).squeeze(0))])\n",
    "\n",
    "    train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "    test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "    # Subset the datasets to the desired number of samples\n",
    "    train_subset = torch.utils.data.Subset(train_dataset, range(n_train))\n",
    "    test_subset = torch.utils.data.Subset(test_dataset, range(n_test))\n",
    "\n",
    "    # Create DataLoaders for training and testing sets\n",
    "    train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "    test_loader = DataLoader(test_subset, batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "\n",
    "    print(\"Number of training samples:\", len(train_subset))\n",
    "    print(\"Number of test samples:\", len(test_subset))\n",
    "\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f805aa90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 6000\n",
      "Number of test samples: 1000\n"
     ]
    }
   ],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "\n",
    "        # Convolutional layer (Maps 1 input channel to 4 output channels)\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=4, kernel_size=2, stride=2)\n",
    "\n",
    "        # Calculate output size: [(W - F + 2P) / S] + 1 = [(14 - 2 + 0) / 2] + 1 = 7\n",
    "        # The output of our conv layer will be 7x7x4 (4 output channels)\n",
    "\n",
    "        # Fully connected layer to perform the final classification\n",
    "        self.fc1 = nn.Linear(7 * 7 * 4, 10)  # Assuming 10 output classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))  # Apply convolution and ReLU activation\n",
    "        x = x.view(-1, 7 * 7 * 4)  # Flatten for the fully connected layer\n",
    "        x = self.fc1(x)\n",
    "        x = F.softmax(x, dim=1)  # Apply softmax\n",
    "        return x\n",
    "\n",
    "model = SimpleCNN()\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")  # Use GPU if available\n",
    "#model.to(device)\n",
    "train_loader, test_loader = load_dataset(n_train, n_test, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4cfbdae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=gamma) \n",
    "loss_fn = F.cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d269cb54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[i] Epoch 1\n",
      "\tLoss: 2.1576\tAccuracy: 34.98%\n",
      "\tVal Loss: 1.9451\t Val Accuracy: 60.40%\n",
      "\tElapsed Time: 0.69s\n",
      "[i] Epoch 2\n",
      "\tLoss: 1.7972\tAccuracy: 72.13%\n",
      "\tVal Loss: 1.7466\t Val Accuracy: 75.00%\n",
      "\tElapsed Time: 0.64s\n",
      "[i] Epoch 3\n",
      "\tLoss: 1.6972\tAccuracy: 79.07%\n",
      "\tVal Loss: 1.7063\t Val Accuracy: 77.60%\n",
      "\tElapsed Time: 0.69s\n",
      "[i] Epoch 4\n",
      "\tLoss: 1.6678\tAccuracy: 81.25%\n",
      "\tVal Loss: 1.6869\t Val Accuracy: 79.00%\n",
      "\tElapsed Time: 0.68s\n",
      "[i] Epoch 5\n",
      "\tLoss: 1.6538\tAccuracy: 82.40%\n",
      "\tVal Loss: 1.6815\t Val Accuracy: 79.60%\n",
      "\tElapsed Time: 0.57s\n",
      "[i] Epoch 6\n",
      "\tLoss: 1.6427\tAccuracy: 83.20%\n",
      "\tVal Loss: 1.6749\t Val Accuracy: 79.50%\n",
      "\tElapsed Time: 0.64s\n",
      "[i] Epoch 7\n",
      "\tLoss: 1.6371\tAccuracy: 83.77%\n",
      "\tVal Loss: 1.6644\t Val Accuracy: 80.60%\n",
      "\tElapsed Time: 0.71s\n",
      "[i] Epoch 8\n",
      "\tLoss: 1.6283\tAccuracy: 84.17%\n",
      "\tVal Loss: 1.6607\t Val Accuracy: 80.70%\n",
      "\tElapsed Time: 0.71s\n",
      "[i] Epoch 9\n",
      "\tLoss: 1.6284\tAccuracy: 84.25%\n",
      "\tVal Loss: 1.6581\t Val Accuracy: 81.00%\n",
      "\tElapsed Time: 0.87s\n",
      "[i] Epoch 10\n",
      "\tLoss: 1.6260\tAccuracy: 84.37%\n",
      "\tVal Loss: 1.6630\t Val Accuracy: 79.90%\n",
      "\tElapsed Time: 0.86s\n",
      "[i] Epoch 11\n",
      "\tLoss: 1.6235\tAccuracy: 84.60%\n",
      "\tVal Loss: 1.6634\t Val Accuracy: 80.50%\n",
      "\tElapsed Time: 0.84s\n",
      "[i] Epoch 12\n",
      "\tLoss: 1.6222\tAccuracy: 84.77%\n",
      "\tVal Loss: 1.6590\t Val Accuracy: 80.40%\n",
      "\tElapsed Time: 0.83s\n",
      "[i] Epoch 13\n",
      "\tLoss: 1.6174\tAccuracy: 85.20%\n",
      "\tVal Loss: 1.6542\t Val Accuracy: 81.10%\n",
      "\tElapsed Time: 0.62s\n",
      "[i] Epoch 14\n",
      "\tLoss: 1.6153\tAccuracy: 85.23%\n",
      "\tVal Loss: 1.6534\t Val Accuracy: 80.50%\n",
      "\tElapsed Time: 0.72s\n",
      "[i] Epoch 15\n",
      "\tLoss: 1.6150\tAccuracy: 85.28%\n",
      "\tVal Loss: 1.6551\t Val Accuracy: 80.70%\n",
      "\tElapsed Time: 0.66s\n",
      "[i] Epoch 16\n",
      "\tLoss: 1.6133\tAccuracy: 85.43%\n",
      "\tVal Loss: 1.6550\t Val Accuracy: 80.40%\n",
      "\tElapsed Time: 0.71s\n",
      "[i] Epoch 17\n",
      "\tLoss: 1.6098\tAccuracy: 85.68%\n",
      "\tVal Loss: 1.6494\t Val Accuracy: 81.40%\n",
      "\tElapsed Time: 0.71s\n",
      "[i] Epoch 18\n",
      "\tLoss: 1.6090\tAccuracy: 85.80%\n",
      "\tVal Loss: 1.6514\t Val Accuracy: 80.90%\n",
      "\tElapsed Time: 0.56s\n",
      "[i] Epoch 19\n",
      "\tLoss: 1.6126\tAccuracy: 85.43%\n",
      "\tVal Loss: 1.6477\t Val Accuracy: 81.20%\n",
      "\tElapsed Time: 0.65s\n",
      "[i] Epoch 20\n",
      "\tLoss: 1.6091\tAccuracy: 85.80%\n",
      "\tVal Loss: 1.6485\t Val Accuracy: 81.10%\n",
      "\tElapsed Time: 0.73s\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "\n",
    "    # ---- Training Phase ----\n",
    "    running_loss = 0.0 \n",
    "    correct = 0  \n",
    "    total = 0\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    start_time = time.time()\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # --- 2. Forward Pass ---\n",
    "        outputs = model(images)\n",
    "\n",
    "        # --- 3. Loss Calculation ---\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        train_losses.append(loss.item())\n",
    "        # --- 4. Backpropagation and Optimization ---\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()  \n",
    "        train_losses.append(loss.item())  # Store loss for each batch\n",
    "\n",
    "        # Accuracy calculation for the epoch\n",
    "        _, predicted = torch.max(outputs.data, 1) \n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    scheduler.step() \n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    val_loss = 0.0\n",
    "    val_corrects = 0\n",
    "    \n",
    "    with torch.no_grad():  # Disable gradients for evaluation\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "\n",
    "        for images, labels in test_loader:\n",
    "            outputs = model(images)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            test_losses.append(loss.item())\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            val_total += labels.size(0)\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    val_loss = sum(test_losses) / len(test_losses)\n",
    "    val_acc = 100 * val_correct / val_total \n",
    "\n",
    "    # Print statistics for the epoch\n",
    "    epoch_loss = sum(train_losses) / len(train_losses)  \n",
    "    epoch_acc = 100 * correct / total \n",
    "\n",
    "    # Periodic Evaluation and Logging\n",
    "    print(f'[i] Epoch {epoch + 1}\\n\\tLoss: {epoch_loss:.4f}\\tAccuracy: {epoch_acc :.2f}%\\n\\tVal Loss: {val_loss:.4f}\\t Val Accuracy: {val_acc :.2f}%\\n\\tElapsed Time: {time.time() - start_time:.2f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498d3d60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
